<!doctype html>
<html>
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <title>Weiting Tan's Homepage</title>

    <link rel="stylesheet" href="stylesheets/styles.css">
    <link rel="stylesheet" href="stylesheets/pygment_trac.css">
    <meta name="viewport" content="width=device-width">
    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
  </head>
  <body>
    <div class="wrapper">
      <header>
        <h1>Weiting (Steven) Tan</h1>
        <p>Ph.D. student @ Johns Hopkins University</p>
        <img src="figures/my_pic.jpg">

        <ul>
          <li><a href="https://twitter.com/weiting_nlp"> <strong>Twitter</strong></a></li>
          <li><a href="https://www.linkedin.com/in/weiting-steven-tan-30bb4a175/"><strong>LinkedIn</strong></a></li>
          <li><a href="https://github.com/steventan0110"><strong>GitHub</strong></a></li>
        </ul>
      </header>
      <section>
        <h2>About Me</h2>
        <p>I am a first year CS PhD student at Center of Language and Speech Processing, Johns Hopkins University, advised by prof. Philipp Koehn. Previously, I obtained BS/MS degree at Johns Hopkins University as well. Go Hop!</p>
        <p>My research interest lies in representation learning for language and speech. Specifically, I am curious about
        <ul>
          <li>How to better learn and utilize representation in low-resource scenarios</li>
          <li>How to align representation from different modalities such as jointly representing language and text</li>
          <li>How to efficiently compress/segment representation for tasks that require long-context window or continuous streams</li>
        </ul>
        </p>

        <h2>Publication</h2>

        <ul>
          <li><strong>Weiting Tan</strong>, Kevin Heffernan, Holger Schwenk, and Philipp Koehn. (2023). Multilingual Representation Distillation with Contrastive Learning. <em>In Proceedings of EACL 2023</em></li>
      
          <li>Lingfeng Shen*, <strong>Weiting Tan*</strong>, Boyuan Zheng, and Daniel Khashabi. (2023). Flatness-Aware Prompt Selection Improves Accuracy and Sample Efficiency. <em>In Findings of EMNLP 2023</em></li>
      
          <li>Haoran Xu, <strong>Weiting Tan</strong>, Shuyue Stella Li, Yunmo Chen, Benjamin Van Durme, Philipp Koehn, and Kenton Murray. (2023). Condensing Multilingual Knowledge with Lightweight Language-Specific Module. <em>In Proceedings of EMNLP 2023</em></li>
      
          <li><strong>Weiting Tan</strong>, Chu-Cheng Lin, and Jason Eisner (2023). Structure-Aware Path Inference for Neural Finite State Transducers. <em>To Appear at ICBINB workshop of NeurIPS 2023</em></li>
      
          <li><strong>Weiting Tan</strong>, Shuoyang Ding, Huda Khayrallah, and Philipp Koehn. (2022). Doubly-Trained Adversarial Data Augmentation for Neural Machine Translation. <em>In Proceedings of the 15th Biennial Conference of the Association for Machine Translation in the Americas 2022</em></li>
        </ul>

        <h2>Manuscripts</h2>
        <ul>
          <li><strong>Weiting Tan</strong>, Eunah Cho, Ziyan Jiang, Tony Chen, Zhengyang Zhao, Gustavo Aguilar, Xing Fan, Wei Shen, and Chenlei Guo (2023). ConvoEval: A Discerning Conversational Response Evaluator Using Large Language Models. <em>In submission to EACL 2024</em></li>
      
          <li>Lingfeng Shen, Boyuan Zheng, Haoran Xu, <strong>Weiting Tan</strong>, Yunmo Chen, Philipp Koehn, and Daniel Khashabi (2023) TECO: Text Evaluation via Closest Paraphrase. <em>In submission to EACL 2024</em></li>
      
          <li><strong>Weiting Tan</strong>, Haoran Xu, Lingfeng Shen, Shuyue Stella Li, Kenton Murray, Philipp Koehn, Benjamin Van Durme, and Yunmo Chen (2023). Narrowing the Gap between Zero- and Few-shot Machine Translation by Matching Styles. <em>In submission to NAACL 2024</em></li>
      
          <li><strong>Weiting Tan</strong> and Philipp Koehn. (2022). Bitext Mining via Contrastive Learning. arXiv abs/2208.11194</li>
        </ul>

        <h2>Teaching</h2>
        <ul>
          <li>EN.601.465 Natural Language Processing (Course Assistant) - Fall 2022</li>
          <li>EN.601.421 Objected-Oriented Software Engineering (Head Course Assistant) - Spring 2021, Fall 2021</li>
          <li>EN.601.280 Full-stack JavaScript (Head Course Assistant) - Fall 2020</li>
          <li>EN.601.226 Data Structures (Course Assistant) - Fall 2019, Spring 2020</li>
        </ul>
        
        <h2>Service</h2>
        <ul>
          <li>Program Chair of The First Workshop on Personalized Generative AI @CIKM'23</li>
          <li>Student Representative of the CS Curriculum Committee at Johns Hopkins University</li>
        </ul>
        <!-- <h2>Crazy linking action</h2>

        <p>I get 10 times more traffic from <a href="http://google.com/" title="Google">Google</a> than from<br>
        <a href="http://search.yahoo.com/" title="Yahoo Search">Yahoo</a> or <a href="http://search.msn.com/" title="MSN Search">MSN</a>.</p> -->
      </section>
      <footer>
        <p><small>Hosted on GitHub Pages &mdash; Theme by <a href="https://github.com/orderedlist">orderedlist</a></small></p>
      </footer>
    </div>
    <script src="javascripts/scale.fix.js"></script>
  </body>
</html>
